-----------------------------------------------------------------------------------------------
[한 줄 요약] Accuracy & speed를 더 높이기 위해서, 새로운 FPN 구조와 training 방식을 제안했음.
-----------------------------------------------------------------------------------------------

1. motivations
- 논문을 읽어보았을 때, 이전 연구들에서 문제점을 찾고 이를 해결하기 위해 연구를 한 것은 아닌 것 같다.
- 연구의 동기는 모델의 inference 속도는 빠르게 유지하면서, accuracy를 높이기 위함이다.

2. contributions
- BiC module과 SimCSPSPPF Block을 도입함으로써, 모델의 Neck 부분이 localization을 더 잘 할 수 있도록 했다.
- Anchor Aided Training(AAT) 전략을 도입하여, inference 효율을 유지하면서 anchor-based 모델과 anchor-free
모델의 장점을 가져왔다.
- self-distilation 전략을 도입하여, YOLO v6의 작은 모델들의 성능 향상을 불러왔다.

3. methods
- BiC module과 SimCSPSPPF Block은 특별한 방법이 있었다기 보다는, 이전 연구들을 기반으로 연산량을 늘리지 않으면서
localization과 representation을 더 잘 표현할 수 있도록 아키텍처를 구현한 것으로 보인다.
(아키텍처를 왜 이렇게 구현했는가? 에 대한 근거는 특별히 나와있지 않음.)
- AAT의 경우, 실험을 하다 보니 anchor-based 모델이 anchor-free 모델과 비교했을 때 동일한 setting에서 성능 향상을
보인다는 것을 관찰했다고 한다. 그래서 anchor-based 모델의 장점(detection 성능)과 anchor-free 모델의 장점(inference 속도)
을 모두 가져오고자 했다.
- Training 과정에서 anchor-based head를 추가해서 detection 성능을 높이고, 실제 inference 시에는 anchor-free head만
사용함으로써 inference 속도의 저하 없이 accuracy를 높였다고 한다.
- self-distilation의 경우 inference 효율성을 떨어뜨리지 않으면서 small model의 성능을 높이기 위해 도입한 전략이다.

4. results
- self-distilation을 적용한 모델의 경우에만 기존 모델들보다 성능이 좋은 것으로 보인다.
